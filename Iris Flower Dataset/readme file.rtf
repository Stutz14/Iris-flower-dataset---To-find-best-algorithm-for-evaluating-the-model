{\rtf1\ansi\ansicpg1252\cocoartf2820
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 .SFNS-Regular_wdth_opsz200000_GRAD_wght2580000;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 .SFNS-Regular_wdth_opsz110000_GRAD_wght2580000;
}
{\colortbl;\red255\green255\blue255;\red237\green244\blue251;\red0\green0\blue0;\red56\green126\blue248;
}
{\*\expandedcolortbl;;\cssrgb\c94359\c96720\c98837;\cssrgb\c0\c1\c1;\cssrgb\c27271\c58364\c97905;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa320\partightenfactor0

\f0\b\fs64 \cf2 \cb3 \expnd0\expndtw0\kerning0
Iris-Project\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs32 \cf2 \cb3 \
\pard\pardeftab720\sa320\partightenfactor0
\cf2 \cb3 A machine learning project is certainly not linear and involves numerous steps which if not implemented carefully, could result in a bad model. The steps required to successfully build an accurate model are as follows:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Define the problem clearly.\
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	2	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Prepare the data.\
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	3	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Evaluate various different kinds of algorithms.\
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	4	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Improve the results obtained.\
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	5	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Present the results.\
\pard\pardeftab720\sa320\partightenfactor0

\f2\b \cf2 \cb3 The dataset used
\f1\b0 \cf2 \cb3 : Iris Flower Dataset ({\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Iris_flower_data_set"}}{\fldrslt \cf4 \cb3 \ul \ulc4 https://en.wikipedia.org/wiki/Iris_flower_data_set}}). There are four columns of measurements of the flowers in centimeters. The fifth column is the species of the flower observed. All observed flowers belong to one of three species.\
To begin with, I played around with the data and obtained numerous discrete summaries (both numerical and graphical). It helped me gain insight of the data at a high level. Summarizing the data proves to be useful in the long run since it gives an overview of the dataset and what to expect.\
There isn't a particular problem to be specified in this project. This project basically showcases how different algorithms can be used on a dataset and how the best algorithm can be found out and used to evaluate the model on unseen data using python.\
The data was cleaned up before many algorithms were tried on it. Technically, this step is called data pre-processing. I cleaned the data by removing any outliers which could affect the data in a huge way and scaled each entry by making mean = 0 and variance = 1 of the dataset. The dataset was then divided into training dataset which comprises about 80% of the transformed dataset and validation dataset which comprises about 20% of the transformed dataset.\
Several algorithms were used in order to successfully compute the best model. The algorithms used are:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Logistic Regression (LR)\
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	2	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Linear Discriminant Analysis (LDA)\
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	3	}\cf2 \cb3 \expnd0\expndtw0\kerning0
K-Nearest Neighbors (KNN).\
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	4	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Classification and Regression Trees (CART).\
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	5	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Gaussian Naive Bayes (NB).\
\ls2\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	6	}\cf2 \cb3 \expnd0\expndtw0\kerning0
Support Vector Machines (SVM)\
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 The best algorithm was selected after careful consideration and the best one was used to evaluate the model on the validation dataset and make predictions.}